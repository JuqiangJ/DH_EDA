<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 6 From data visualization to statistical modelling | A Introduction to Eploratory Data Analysis with R</title>
  <meta name="description" content="This is an introduction to Eploratory Data Analysis with R tutorial for DH summer school 2019 at Newcastle.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 6 From data visualization to statistical modelling | A Introduction to Eploratory Data Analysis with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is an introduction to Eploratory Data Analysis with R tutorial for DH summer school 2019 at Newcastle." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 From data visualization to statistical modelling | A Introduction to Eploratory Data Analysis with R" />
  
  <meta name="twitter:description" content="This is an introduction to Eploratory Data Analysis with R tutorial for DH summer school 2019 at Newcastle." />
  

<meta name="author" content="Juqiang Chen">


<meta name="date" content="2019-12-01">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="covariation.html">
<link rel="next" href="parametric-tests-and-relevant-assumptions.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Exploratory Data Analysis with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#installing-r-and-r-studio"><i class="fa fa-check"></i><b>1.1</b> Installing R and R studio</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#install-packages-and-library-packages"><i class="fa fa-check"></i><b>1.2</b> Install packages and library packages</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#data-and-workbook"><i class="fa fa-check"></i><b>1.3</b> Data and workbook</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Basic data structures in R</a><ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#types-of-variables-a-taxonomy"><i class="fa fa-check"></i><b>2.1</b> Types of variables: A taxonomy</a><ul>
<li class="chapter" data-level="2.1.1" data-path="intro.html"><a href="intro.html#categorical-variables-ordinal-vs.norminal"><i class="fa fa-check"></i><b>2.1.1</b> Categorical variables: ordinal vs. norminal</a></li>
<li class="chapter" data-level="2.1.2" data-path="intro.html"><a href="intro.html#numeric-variables-discrete-or-continuous"><i class="fa fa-check"></i><b>2.1.2</b> Numeric variables: discrete or continuous</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#d-data-structure-vectors"><i class="fa fa-check"></i><b>2.2</b> 1D data structure: vectors</a><ul>
<li class="chapter" data-level="2.2.1" data-path="intro.html"><a href="intro.html#creating-vectors"><i class="fa fa-check"></i><b>2.2.1</b> Creating vectors</a></li>
<li class="chapter" data-level="2.2.2" data-path="intro.html"><a href="intro.html#creating-list-objects"><i class="fa fa-check"></i><b>2.2.2</b> Creating list objects</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#d-data-structures-matrice-and-data-frames"><i class="fa fa-check"></i><b>2.3</b> 2D data structures: matrice and data frames</a><ul>
<li class="chapter" data-level="2.3.1" data-path="intro.html"><a href="intro.html#what-if-i-want-to-change-column-names-or-add-variable-to-the-df"><i class="fa fa-check"></i><b>2.3.1</b> what if I want to change column names or add variable to the df?</a></li>
<li class="chapter" data-level="2.3.2" data-path="intro.html"><a href="intro.html#subsetting-dataframes"><i class="fa fa-check"></i><b>2.3.2</b> Subsetting dataframes</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="intro.html"><a href="intro.html#summary"><i class="fa fa-check"></i><b>2.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="what-is-eda.html"><a href="what-is-eda.html"><i class="fa fa-check"></i><b>3</b> What is EDA?</a><ul>
<li class="chapter" data-level="3.1" data-path="what-is-eda.html"><a href="what-is-eda.html#definition-from-wikipedia"><i class="fa fa-check"></i><b>3.1</b> Definition (from Wikipedia)</a></li>
<li class="chapter" data-level="3.2" data-path="what-is-eda.html"><a href="what-is-eda.html#the-objectives-of-eda"><i class="fa fa-check"></i><b>3.2</b> The objectives of EDA</a></li>
<li class="chapter" data-level="3.3" data-path="what-is-eda.html"><a href="what-is-eda.html#data-analysis-workflow"><i class="fa fa-check"></i><b>3.3</b> Data analysis workflow</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="variation.html"><a href="variation.html"><i class="fa fa-check"></i><b>4</b> Variation</a><ul>
<li class="chapter" data-level="4.1" data-path="variation.html"><a href="variation.html#categorical-variable"><i class="fa fa-check"></i><b>4.1</b> Categorical variable</a><ul>
<li class="chapter" data-level="4.1.1" data-path="variation.html"><a href="variation.html#absolute-v.s-relative-frequency"><i class="fa fa-check"></i><b>4.1.1</b> Absolute v.s relative frequency?</a></li>
<li class="chapter" data-level="4.1.2" data-path="variation.html"><a href="variation.html#frequency-distributions"><i class="fa fa-check"></i><b>4.1.2</b> Frequency distributions</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="variation.html"><a href="variation.html#continous-variable"><i class="fa fa-check"></i><b>4.2</b> Continous variable</a><ul>
<li class="chapter" data-level="4.2.1" data-path="variation.html"><a href="variation.html#central-tendency"><i class="fa fa-check"></i><b>4.2.1</b> Central tendency</a></li>
<li class="chapter" data-level="4.2.2" data-path="variation.html"><a href="variation.html#measures-of-spread"><i class="fa fa-check"></i><b>4.2.2</b> Measures of Spread</a></li>
<li class="chapter" data-level="4.2.3" data-path="variation.html"><a href="variation.html#confidence-interval"><i class="fa fa-check"></i><b>4.2.3</b> Confidence interval</a></li>
<li class="chapter" data-level="4.2.4" data-path="variation.html"><a href="variation.html#unusual-values"><i class="fa fa-check"></i><b>4.2.4</b> Unusual values</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="covariation.html"><a href="covariation.html"><i class="fa fa-check"></i><b>5</b> Covariation</a><ul>
<li class="chapter" data-level="5.1" data-path="covariation.html"><a href="covariation.html#two-categorical-variables"><i class="fa fa-check"></i><b>5.1</b> Two categorical variables</a><ul>
<li class="chapter" data-level="5.1.1" data-path="covariation.html"><a href="covariation.html#contingency-table"><i class="fa fa-check"></i><b>5.1.1</b> Contingency table</a></li>
<li class="chapter" data-level="5.1.2" data-path="covariation.html"><a href="covariation.html#tile-plot"><i class="fa fa-check"></i><b>5.1.2</b> Tile plot</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="covariation.html"><a href="covariation.html#categorical-continuous-variable"><i class="fa fa-check"></i><b>5.2</b> Categorical + continuous variable</a><ul>
<li class="chapter" data-level="5.2.1" data-path="covariation.html"><a href="covariation.html#summary-table"><i class="fa fa-check"></i><b>5.2.1</b> Summary table</a></li>
<li class="chapter" data-level="5.2.2" data-path="covariation.html"><a href="covariation.html#central-tendency-mean-bar-plots"><i class="fa fa-check"></i><b>5.2.2</b> Central tendency (mean): Bar plots</a></li>
<li class="chapter" data-level="5.2.3" data-path="covariation.html"><a href="covariation.html#distribution-density-plot"><i class="fa fa-check"></i><b>5.2.3</b> Distribution: density plot</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="covariation.html"><a href="covariation.html#two-continuous-variables"><i class="fa fa-check"></i><b>5.3</b> Two continuous variables</a><ul>
<li class="chapter" data-level="5.3.1" data-path="covariation.html"><a href="covariation.html#scatter-plots"><i class="fa fa-check"></i><b>5.3.1</b> Scatter plots</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="from-data-visualization-to-statistical-modelling.html"><a href="from-data-visualization-to-statistical-modelling.html"><i class="fa fa-check"></i><b>6</b> From data visualization to statistical modelling</a><ul>
<li class="chapter" data-level="6.1" data-path="from-data-visualization-to-statistical-modelling.html"><a href="from-data-visualization-to-statistical-modelling.html#two-continuous-variables-1"><i class="fa fa-check"></i><b>6.1</b> Two continuous variables</a><ul>
<li class="chapter" data-level="6.1.1" data-path="from-data-visualization-to-statistical-modelling.html"><a href="from-data-visualization-to-statistical-modelling.html#simple-linear-regression"><i class="fa fa-check"></i><b>6.1.1</b> Simple linear regression</a></li>
<li class="chapter" data-level="6.1.2" data-path="from-data-visualization-to-statistical-modelling.html"><a href="from-data-visualization-to-statistical-modelling.html#correlation-vs.linear-regression"><i class="fa fa-check"></i><b>6.1.2</b> correlation vs. linear regression</a></li>
<li class="chapter" data-level="6.1.3" data-path="from-data-visualization-to-statistical-modelling.html"><a href="from-data-visualization-to-statistical-modelling.html#correlation-matrix"><i class="fa fa-check"></i><b>6.1.3</b> Correlation matrix</a></li>
<li class="chapter" data-level="6.1.4" data-path="from-data-visualization-to-statistical-modelling.html"><a href="from-data-visualization-to-statistical-modelling.html#pearson-spearman-and-kendall-regression"><i class="fa fa-check"></i><b>6.1.4</b> Pearson, Spearman, and Kendall regression</a></li>
<li class="chapter" data-level="6.1.5" data-path="from-data-visualization-to-statistical-modelling.html"><a href="from-data-visualization-to-statistical-modelling.html#linear-regression"><i class="fa fa-check"></i><b>6.1.5</b> Linear regression</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="from-data-visualization-to-statistical-modelling.html"><a href="from-data-visualization-to-statistical-modelling.html#categoricalindependent-with-continuousdependent"><i class="fa fa-check"></i><b>6.2</b> Categorical(independent) with continuous(dependent)</a><ul>
<li class="chapter" data-level="6.2.1" data-path="from-data-visualization-to-statistical-modelling.html"><a href="from-data-visualization-to-statistical-modelling.html#t-tests"><i class="fa fa-check"></i><b>6.2.1</b> T-tests</a></li>
<li class="chapter" data-level="6.2.2" data-path="from-data-visualization-to-statistical-modelling.html"><a href="from-data-visualization-to-statistical-modelling.html#anova"><i class="fa fa-check"></i><b>6.2.2</b> ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="from-data-visualization-to-statistical-modelling.html"><a href="from-data-visualization-to-statistical-modelling.html#two-categorical-variables-1"><i class="fa fa-check"></i><b>6.3</b> Two categorical variables</a><ul>
<li class="chapter" data-level="6.3.1" data-path="from-data-visualization-to-statistical-modelling.html"><a href="from-data-visualization-to-statistical-modelling.html#chisquare-t-test"><i class="fa fa-check"></i><b>6.3.1</b> Chisquare t-test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="parametric-tests-and-relevant-assumptions.html"><a href="parametric-tests-and-relevant-assumptions.html"><i class="fa fa-check"></i><b>7</b> Parametric tests and relevant assumptions</a><ul>
<li class="chapter" data-level="7.1" data-path="parametric-tests-and-relevant-assumptions.html"><a href="parametric-tests-and-relevant-assumptions.html#parametric-statistical-tests"><i class="fa fa-check"></i><b>7.1</b> Parametric statistical tests</a></li>
<li class="chapter" data-level="7.2" data-path="parametric-tests-and-relevant-assumptions.html"><a href="parametric-tests-and-relevant-assumptions.html#assumptions"><i class="fa fa-check"></i><b>7.2</b> Assumptions</a><ul>
<li class="chapter" data-level="7.2.1" data-path="parametric-tests-and-relevant-assumptions.html"><a href="parametric-tests-and-relevant-assumptions.html#random-sampling"><i class="fa fa-check"></i><b>7.2.1</b> Random sampling</a></li>
<li class="chapter" data-level="7.2.2" data-path="parametric-tests-and-relevant-assumptions.html"><a href="parametric-tests-and-relevant-assumptions.html#independent-observations"><i class="fa fa-check"></i><b>7.2.2</b> Independent observations</a></li>
<li class="chapter" data-level="7.2.3" data-path="parametric-tests-and-relevant-assumptions.html"><a href="parametric-tests-and-relevant-assumptions.html#normal-distribution-of-data-or-residuals"><i class="fa fa-check"></i><b>7.2.3</b> Normal distribution of data or residuals</a></li>
<li class="chapter" data-level="7.2.4" data-path="parametric-tests-and-relevant-assumptions.html"><a href="parametric-tests-and-relevant-assumptions.html#homogeneity-of-variance"><i class="fa fa-check"></i><b>7.2.4</b> Homogeneity of variance</a></li>
<li class="chapter" data-level="7.2.5" data-path="parametric-tests-and-relevant-assumptions.html"><a href="parametric-tests-and-relevant-assumptions.html#additivity-of-treatment-effects"><i class="fa fa-check"></i><b>7.2.5</b> Additivity of treatment effects</a></li>
<li class="chapter" data-level="7.2.6" data-path="parametric-tests-and-relevant-assumptions.html"><a href="parametric-tests-and-relevant-assumptions.html#outliers"><i class="fa fa-check"></i><b>7.2.6</b> Outliers</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="parametric-tests-and-relevant-assumptions.html"><a href="parametric-tests-and-relevant-assumptions.html#assessing-model-assumptions"><i class="fa fa-check"></i><b>7.3</b> Assessing model assumptions</a><ul>
<li class="chapter" data-level="7.3.1" data-path="parametric-tests-and-relevant-assumptions.html"><a href="parametric-tests-and-relevant-assumptions.html#normality-of-residuals"><i class="fa fa-check"></i><b>7.3.1</b> Normality of residuals</a></li>
<li class="chapter" data-level="7.3.2" data-path="parametric-tests-and-relevant-assumptions.html"><a href="parametric-tests-and-relevant-assumptions.html#skew-and-kurtosis"><i class="fa fa-check"></i><b>7.3.2</b> Skew and kurtosis</a></li>
<li class="chapter" data-level="7.3.3" data-path="parametric-tests-and-relevant-assumptions.html"><a href="parametric-tests-and-relevant-assumptions.html#visual-inspection-to-assess-the-normality-of-residuals"><i class="fa fa-check"></i><b>7.3.3</b> Visual inspection to assess the normality of residuals</a></li>
<li class="chapter" data-level="7.3.4" data-path="parametric-tests-and-relevant-assumptions.html"><a href="parametric-tests-and-relevant-assumptions.html#visual-inspection-for-homogeneity-of-variance"><i class="fa fa-check"></i><b>7.3.4</b> Visual inspection for homogeneity of variance</a></li>
<li class="chapter" data-level="7.3.5" data-path="parametric-tests-and-relevant-assumptions.html"><a href="parametric-tests-and-relevant-assumptions.html#formal-tests-for-homogeneity-of-variance"><i class="fa fa-check"></i><b>7.3.5</b> formal tests for homogeneity of variance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="resources-for-eda.html"><a href="resources-for-eda.html"><i class="fa fa-check"></i><b>8</b> Resources for EDA</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Introduction to Eploratory Data Analysis with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="from-data-visualization-to-statistical-modelling" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> From data visualization to statistical modelling</h1>
<p>Patterns in the data provide clues about relationship or covariation.Now that we know how to visualize the various relationships, we can proceed to learn more about how to formally test the relationship.</p>
<p>Statistical models are tools for extracting patterns out of data.</p>
<p>Statistics represent a common method of presenting information helping us to understand what the data are telling us.</p>
<ul>
<li><p><em>Descriptive (or summary) statistics</em> summarise the raw data and allow data users to interpret a dataset more easily.Descriptive statistics can describe the shape, centre and spread of a dataset.</p></li>
<li><p><em>Inferential statistics</em> are used to infer conclusions about a <strong>population</strong> from a <strong>sample</strong> of that population. It includes <em>estimation</em> (An estimate is a value that is inferred for a population based on data collected from a sample of units from that population), and <em>hypothesis testing</em>.</p></li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:stats"></span>
<img src="img/stats.png" alt="stats" width="100%" />
<p class="caption">
Figure 6.1: stats
</p>
</div>
<div id="two-continuous-variables-1" class="section level2">
<h2><span class="header-section-number">6.1</span> Two continuous variables</h2>
<div id="simple-linear-regression" class="section level3">
<h3><span class="header-section-number">6.1.1</span> Simple linear regression</h3>
<p>The techique we used here is called <em>Simple linear regression</em>, where there is one dependent variable (continuous) and one independent variable (continuous). When there are more than one independent variable (continuous), you need to look for something called <em>Multiple linear regression</em>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(faithful)</code></pre></div>
<pre><code>##   eruptions waiting
## 1     3.600      79
## 2     1.800      54
## 3     3.333      74
## 4     2.283      62
## 5     4.533      85
## 6     2.883      55</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(faithful)<span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(eruptions, waiting))</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
</div>
<div id="correlation-vs.linear-regression" class="section level3">
<h3><span class="header-section-number">6.1.2</span> correlation vs. linear regression</h3>
<p><em>Correlation</em> and <em>linear regression</em> each explore the relationship between two quantitative variables. (Salvatore S. Mangiafico)</p>
<ul>
<li><p>Correlation determines if one variable varies systematically as another variable changes. It does not specify that one variable is the dependent variable and the other is the independent variable. Often, it is useful to look at which variables are correlated to others in a data set, and it is especially useful to see which variables correlate to a particular variable of interest.</p></li>
<li><p>In contrast, linear regression specifies one variable as the independent variable and another as the dependent variable. The resultant model relates the variables with a linear relationship.</p></li>
</ul>
<p>The tests associated with linear regression are parametric and assume normality, homoscedasticity, and independence of residuals, as well as a linear relationship between the two variables.</p>
</div>
<div id="correlation-matrix" class="section level3">
<h3><span class="header-section-number">6.1.3</span> Correlation matrix</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pairs</span>(<span class="dt">data=</span>faithful,
    <span class="op">~</span><span class="st"> </span>eruptions <span class="op">+</span><span class="st"> </span>waiting)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pairs</span>(<span class="dt">data=</span>iris,
    <span class="op">~</span><span class="st"> </span>Sepal.Length <span class="op">+</span><span class="st"> </span>Sepal.Width <span class="op">+</span><span class="st"> </span>Petal.Length <span class="op">+</span>Petal.Width)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-40-2.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">corr.test</span>(faithful,
          <span class="dt">use    =</span> <span class="st">&quot;pairwise&quot;</span>,
          <span class="dt">method =</span> <span class="st">&quot;pearson&quot;</span>,
          <span class="dt">adjust =</span> <span class="st">&quot;none&quot;</span>)</code></pre></div>
<pre><code>## Call:corr.test(x = faithful, use = &quot;pairwise&quot;, method = &quot;pearson&quot;, 
##     adjust = &quot;none&quot;)
## Correlation matrix 
##           eruptions waiting
## eruptions       1.0     0.9
## waiting         0.9     1.0
## Sample Size 
## [1] 272
## Probability values (Entries above the diagonal are adjusted for multiple tests.) 
##           eruptions waiting
## eruptions         0       0
## waiting           0       0
## 
##  To see confidence intervals of the correlations, print with the short=FALSE option</code></pre>
</div>
<div id="pearson-spearman-and-kendall-regression" class="section level3">
<h3><span class="header-section-number">6.1.4</span> Pearson, Spearman, and Kendall regression</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># library(PerformanceAnalytics)</span>
<span class="kw">chart.Correlation</span>(faithful,
                   <span class="dt">method=</span><span class="st">&quot;pearson&quot;</span>,
                   <span class="dt">histogram=</span><span class="ot">TRUE</span>,
                   <span class="dt">pch=</span><span class="dv">16</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-41-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">chart.Correlation</span>(faithful,
                   <span class="dt">method=</span><span class="st">&quot;kendall&quot;</span>,
                   <span class="dt">histogram=</span><span class="ot">TRUE</span>,
                   <span class="dt">pch=</span><span class="dv">16</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-41-2.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">chart.Correlation</span>(faithful,
                   <span class="dt">method=</span><span class="st">&quot;spearman&quot;</span>,
                   <span class="dt">histogram=</span><span class="ot">TRUE</span>,
                   <span class="dt">pch=</span><span class="dv">16</span>)</code></pre></div>
<pre><code>## Warning in cor.test.default(as.numeric(x), as.numeric(y), method = method):
## Cannot compute exact p-value with ties</code></pre>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-41-3.png" width="672" /></p>
<div id="effect-size" class="section level4">
<h4><span class="header-section-number">6.1.4.1</span> Effect size</h4>
<p>The statistics r, rho, and tau are used as effect sizes for Pearson, Spearman, and Kendall regression, respectively. These statistics vary from –1 to 1, with 0 indicating no correlation, 1 indicating a perfect positive correlation, and –1 indicating a perfect negative correlation. Like other effect size statistics, these statistics are not affected by sample size.</p>
<p>Interpretation of effect sizes necessarily varies by discipline and the expectations of the experiment. They should not be considered universal. An interpretation of r is given by Cohen (1988). It is probably reasonable to use similar interpretations for rho and tau.</p>
<ul>
<li><p>small: 0.10 – &lt; 0.30</p></li>
<li><p>medium: 0.30 – &lt; 0.50</p></li>
<li><p>large: ≥ 0.50</p></li>
</ul>
</div>
<div id="pearson-correlation" class="section level4">
<h4><span class="header-section-number">6.1.4.2</span> Pearson correlation</h4>
<p>The test used for <em>Pearson correlation</em> is a parametric analysis that requires that the relationship between the variables is linear, and that the data be bivariate normal. Variables should be interval/ratio. The test is sensitive to outliers.</p>
<p>The correlation coefficient, r, can range from +1 to –1, with +1 being a perfect positive correlation and –1 being a perfect negative correlation. An r of 0 represents no correlation whatsoever. The hypothesis test determines if the r value is significantly different from 0.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor.test</span>( <span class="op">~</span><span class="st"> </span>eruptions <span class="op">+</span><span class="st"> </span>waiting,
         <span class="dt">data=</span>faithful,
         <span class="dt">method =</span> <span class="st">&quot;pearson&quot;</span>)</code></pre></div>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  eruptions and waiting
## t = 34.089, df = 270, p-value &lt; 2.2e-16
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.8756964 0.9210652
## sample estimates:
##       cor 
## 0.9008112</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># the results report the p-value for the hypothesis test as well as the r value, written as cor, 0.849.</span></code></pre></div>
</div>
<div id="kendall-correlation" class="section level4">
<h4><span class="header-section-number">6.1.4.3</span> Kendall correlation</h4>
<p><em>Kendall correlation </em>is considered a nonparametric analysis. - It is a rank-based test that does not require assumptions about the distribution of the data.<br />
- Variables can be interval/ratio or ordinal.</p>
<p>The correlation coefficient from the test is tau, which can range from +1 to –1, with +1 being a perfect positive correlation and –1 being a perfect negative correlation. A tau of 0 represents no correlation whatsoever. The hypothesis test determines if the tau value is significantly different from 0.</p>
<p>As a technical note, the <em>cor.test</em> function in R calculates tau-b, which handles ties in ranks well.</p>
<p>The test is relatively robust to outliers in the data. The test is sometimes cited for being reliable when there are small number of samples or when there are many ties in ranks.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor.test</span>( <span class="op">~</span><span class="st"> </span>eruptions <span class="op">+</span><span class="st"> </span>waiting,
         <span class="dt">data=</span>faithful,
         <span class="dt">method =</span> <span class="st">&quot;kendall&quot;</span>)</code></pre></div>
<pre><code>## 
##  Kendall&#39;s rank correlation tau
## 
## data:  eruptions and waiting
## z = 13.902, p-value &lt; 2.2e-16
## alternative hypothesis: true tau is not equal to 0
## sample estimates:
##       tau 
## 0.5747674</code></pre>
</div>
<div id="spearman-correlation" class="section level4">
<h4><span class="header-section-number">6.1.4.4</span> Spearman correlation</h4>
<p><em>Spearman correlation</em> is considered a nonparametric analysis.</p>
<ul>
<li>It is a rank-based test that does not require assumptions about the distribution of the data.<br />
</li>
<li>Variables can be interval/ratio or ordinal.</li>
</ul>
<p>The correlation coefficient from the test, rho, can range from +1 to –1, with +1 being a perfect positive correlation and –1 being a perfect negative correlation. A rho of 0 represents no correlation whatsoever. The hypothesis test determines if the rho value is significantly different from 0.</p>
<p>Spearman correlation is probably most often used with ordinal data. It tests for a monotonic relationship between the variables. It is relatively robust to outliers in the data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor.test</span>( <span class="op">~</span><span class="st"> </span>eruptions <span class="op">+</span><span class="st"> </span>waiting,
         <span class="dt">data=</span>faithful,
         <span class="dt">method =</span> <span class="st">&quot;spearman&quot;</span>)</code></pre></div>
<pre><code>## Warning in cor.test.default(x = c(3.6, 1.8, 3.333, 2.283, 4.533, 2.883, :
## Cannot compute exact p-value with ties</code></pre>
<pre><code>## 
##  Spearman&#39;s rank correlation rho
## 
## data:  eruptions and waiting
## S = 744660, p-value &lt; 2.2e-16
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##       rho 
## 0.7779721</code></pre>
</div>
</div>
<div id="linear-regression" class="section level3">
<h3><span class="header-section-number">6.1.5</span> Linear regression</h3>
<p>Linear regression is a very common approach to model the relationship between two interval/ratio variables. The outcome of linear regression includes estimating the <em>intercept</em> and the <em>slope</em> of the linear model.</p>
<p>Multiple, nominal, and ordinal independent variables</p>
<ul>
<li><p>If there are multiple independent variables of interval/ratio type in the model, then linear regression expands to multiple regression.</p></li>
<li><p>If the independent variable were of nominal type, then the linear regression would become a <em>one-way analysis of variance</em>.</p></li>
<li><p>Handling independent variables of ordinal type can be complicated. Often they are treated as either nominal type or interval/ratio type, although there are drawbacks to each approach.</p></li>
</ul>
<p>Assumptions</p>
<p>Linear regression assumes - a linear relationship between the two variables, - normality of the residuals, - independence of the residuals, - homoscedasticity of residuals.</p>
<p>Linear regression can be performed with the lm function, which was the same function we used for analysis of variance.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model =<span class="st"> </span><span class="kw">lm</span>(eruptions <span class="op">~</span><span class="st"> </span>waiting,
           <span class="dt">data =</span> faithful)

<span class="kw">summary</span>(model)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = eruptions ~ waiting, data = faithful)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.29917 -0.37689  0.03508  0.34909  1.19329 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -1.874016   0.160143  -11.70   &lt;2e-16 ***
## waiting      0.075628   0.002219   34.09   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.4965 on 270 degrees of freedom
## Multiple R-squared:  0.8115, Adjusted R-squared:  0.8108 
## F-statistic:  1162 on 1 and 270 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The <em>summary</em> function for lm model objects includes estimates for model parameters (intercept and slope), as well as an r-squared value for the model and p-value for the model.</p>
<ul>
<li>How to read the model?</li>
</ul>
<p>The model produces a coefficient for the intercept (-1.87) and a coefficient for the slope (0.07);</p>
<p>Each coefficient comes with three other numbers: its standard error, a t-value, and a p-value. The p-value tells us whether the coefficient is significantly different from zero.</p>
<p>If the coefficient for a predictor is zero, there is no relation at all between the predictor and the dependent variable, in which case it is worthless as a predictor. In order to ascertain whether a coefficient is significantly different from zero, and hence potentially useful, a two-tailed t-test is carried out, using the t-value and <em>the associated degrees of freedom</em>.</p>
<p>The t-value itself is the value of the coefficient divided by its standard error. This standard error is a measure of how sure we are about the estimate of the coefficient. The smaller the standard error, the smaller the confidence interval around the estimate, the less likely it is that zero will be included in the acceptance region, and hence the smaller the probability that it might just as well be zero.</p>
<p>The residual standard error is a measure of how unsuccessful the model is; it gauges the variability in the dependent variable that we can’t handle through the predictor variables. The better a model is, the smaller its residual standard error will be.</p>
<p>The multiple R-squared equals 0.8115. This R-squared is the squared correlation coefficient, r2, which quantifies, on a scale from 0 to 1, the proportion of the variance that the model explains.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(eruptions <span class="op">~</span><span class="st"> </span>waiting,
     <span class="dt">data=</span>faithful,
     <span class="dt">pch=</span><span class="dv">16</span>,
     <span class="dt">xlab =</span> <span class="st">&quot;waiting&quot;</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;eruptions&quot;</span>)

<span class="kw">abline</span>(model,
       <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>,
       <span class="dt">lwd =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-46-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x =<span class="st"> </span><span class="kw">residuals</span>(model)


<span class="co">#library(rcompanion)</span>

<span class="kw">plotNormalHistogram</span>(x)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-46-2.png" width="672" /></p>
</div>
</div>
<div id="categoricalindependent-with-continuousdependent" class="section level2">
<h2><span class="header-section-number">6.2</span> Categorical(independent) with continuous(dependent)</h2>
<div id="t-tests" class="section level3">
<h3><span class="header-section-number">6.2.1</span> T-tests</h3>
<p>T-tests are commonly used to compare the means of two samples or between one sample and a fixed value. In other words, the independent variable should be categorical and have two levels.</p>
<div id="requirements" class="section level4">
<h4><span class="header-section-number">6.2.1.1</span> Requirements:</h4>
<ol style="list-style-type: decimal">
<li><p>Observations between groups are independent.That is, not paired or repeated measures data</p></li>
<li><p>Data for each population are normally distributed.Moderate skewness is permissible if the data distribution is unimodal without outliers.</p></li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># distribution</span>
<span class="kw">plot</span>(<span class="kw">density</span>(df<span class="op">$</span>chinese))</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-48-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qqnorm</span>(df<span class="op">$</span>chinese)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-48-2.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># formal tests</span>
<span class="co"># null hypothesis: the distribution is normal</span>
<span class="kw">shapiro.test</span>(df<span class="op">$</span>chinese)</code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  df$chinese
## W = 0.99098, p-value = 0.7435</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ks.test</span>(df<span class="op">$</span>chinese, <span class="st">&quot;pnorm&quot;</span>, <span class="kw">mean</span>(df<span class="op">$</span>chinese), <span class="kw">sd</span>(df<span class="op">$</span>chinese))</code></pre></div>
<pre><code>## 
##  One-sample Kolmogorov-Smirnov test
## 
## data:  df$chinese
## D = 0.052841, p-value = 0.9428
## alternative hypothesis: two-sided</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>For Student’s t-test, the two samples need to have the same variance. However, Welch’s t-test, which is used by default in R, does not assume equal variances.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#independent sample t-test---compare means</span>
class1 =<span class="st"> </span>df[df<span class="op">$</span>class <span class="op">==</span><span class="st"> </span><span class="dv">1</span>, ]<span class="op">$</span>chinese
class2 =<span class="st"> </span>df[df<span class="op">$</span>class <span class="op">==</span><span class="st"> </span><span class="dv">2</span>, ]<span class="op">$</span>chinese

<span class="kw">var.test</span>(class1,class2)<span class="co">#compare variance</span></code></pre></div>
<pre><code>## 
##  F test to compare two variances
## 
## data:  class1 and class2
## F = 1.0919, num df = 24, denom df = 24, p-value = 0.8313
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
##  0.4811483 2.4777307
## sample estimates:
## ratio of variances 
##           1.091859</code></pre>
</div>
<div id="one-sample-t-test" class="section level4">
<h4><span class="header-section-number">6.2.1.2</span> One-sample t-test</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#one sample t-test: one group and a fixed value</span>

<span class="kw">t.test</span>(df<span class="op">$</span>chinese, <span class="dt">mu =</span> <span class="dv">78</span>)</code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  df$chinese
## t = 3.5865, df = 99, p-value = 0.0005227
## alternative hypothesis: true mean is not equal to 78
## 95 percent confidence interval:
##  78.69426 80.41380
## sample estimates:
## mean of x 
##  79.55403</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(df<span class="op">$</span>chinese, <span class="dt">mu =</span> <span class="dv">78</span>, <span class="dt">alternative =</span> <span class="st">&quot;greater&quot;</span>)</code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  df$chinese
## t = 3.5865, df = 99, p-value = 0.0002614
## alternative hypothesis: true mean is greater than 78
## 95 percent confidence interval:
##  78.83458      Inf
## sample estimates:
## mean of x 
##  79.55403</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(df<span class="op">$</span>chinese, <span class="dt">mu =</span> <span class="dv">78</span>, <span class="dt">alternative =</span> <span class="st">&quot;less&quot;</span>)</code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  df$chinese
## t = 3.5865, df = 99, p-value = 0.9997
## alternative hypothesis: true mean is less than 78
## 95 percent confidence interval:
##      -Inf 80.27349
## sample estimates:
## mean of x 
##  79.55403</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">wilcox.test</span>(df<span class="op">$</span>chinese, <span class="dt">mu =</span> <span class="dv">78</span>)<span class="co"># skewed distributions</span></code></pre></div>
<pre><code>## 
##  Wilcoxon signed rank test with continuity correction
## 
## data:  df$chinese
## V = 3515, p-value = 0.0006684
## alternative hypothesis: true location is not equal to 78</code></pre>
</div>
<div id="independent-sample-t-test" class="section level4">
<h4><span class="header-section-number">6.2.1.3</span> Independent sample t-test</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(class1,class2)</code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  class1 and class2
## t = 0.099817, df = 47.908, p-value = 0.9209
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -2.447513  2.703205
## sample estimates:
## mean of x mean of y 
##  79.29556  79.16771</code></pre>
</div>
<div id="paired-sample-t-test" class="section level4">
<h4><span class="header-section-number">6.2.1.4</span> Paired sample t-test</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(df<span class="op">$</span>chinese, df<span class="op">$</span>math, <span class="dt">paired =</span> T)</code></pre></div>
<pre><code>## 
##  Paired t-test
## 
## data:  df$chinese and df$math
## t = 35.906, df = 99, p-value &lt; 2.2e-16
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  18.70386 20.89199
## sample estimates:
## mean of the differences 
##                19.79793</code></pre>
</div>
<div id="wilcox.test" class="section level4">
<h4><span class="header-section-number">6.2.1.5</span> wilcox.test</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">wilcox.test</span>(class1,class2)<span class="co">#not normally distributed</span></code></pre></div>
<pre><code>## 
##  Wilcoxon rank sum test
## 
## data:  class1 and class2
## W = 322, p-value = 0.8626
## alternative hypothesis: true location shift is not equal to 0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">wilcox.test</span>(df<span class="op">$</span>chinese, df<span class="op">$</span>math, <span class="dt">paired =</span> T)</code></pre></div>
<pre><code>## 
##  Wilcoxon signed rank test with continuity correction
## 
## data:  df$chinese and df$math
## V = 5050, p-value &lt; 2.2e-16
## alternative hypothesis: true location shift is not equal to 0</code></pre>
</div>
</div>
<div id="anova" class="section level3">
<h3><span class="header-section-number">6.2.2</span> ANOVA</h3>
<p>When the independent variable has more than two levels, we need to use ANOVA.</p>
<p>We can use <em>avo</em> function in R or build a linear model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dif_class =<span class="st"> </span><span class="kw">aov</span> (chinese <span class="op">~</span><span class="st"> </span>class, <span class="dt">data =</span> df)
<span class="kw">summary</span>(dif_class)</code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value Pr(&gt;F)
## class        3   66.4   22.13   1.185  0.319
## Residuals   96 1792.3   18.67</code></pre>
<p>How to report: There is a significant difference among different classes in terms of their Chinese scores, F (3, 96) = 0.87, p = .46.</p>
<p>After we run the model, it is very likely that we need to conduct pairwised comparison. However, we cannot simple use multiple t-tests but we need to correct the alpha value.</p>
<p>There are different ways to do the correction:</p>
<ul>
<li>Bonferroni correction: a/n</li>
<li>Tukey’s Honestly Significant difference: assuming the means for each level of the factor should be based on equal numbers of observation.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#how is the difference like?</span>
<span class="kw">TukeyHSD</span>(dif_class)</code></pre></div>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = chinese ~ class, data = df)
## 
## $class
##           diff       lwr      upr     p adj
## 2-1 -0.1278461 -3.323258 3.067566 0.9995874
## 3-1 -0.4755548 -3.670967 2.719857 0.9798784
## 4-1  1.6373085 -1.558104 4.832721 0.5401502
## 3-2 -0.3477087 -3.543121 2.847703 0.9919199
## 4-2  1.7651545 -1.430258 4.960567 0.4751527
## 4-3  2.1128632 -1.082549 5.308275 0.3145544</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># diff= the difference in the means</span>
<span class="co"># lwr = the lower end points of the confidence interval</span>
<span class="co"># p adj = adjusted p value</span>

<span class="kw">plot</span>(<span class="kw">TukeyHSD</span>(dif_class))</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-55-1.png" width="672" /></p>
<p>In the general linear model approach, residuals are normally distributed;groups should have the same variance, or homoscedasticity.</p>
<p>Observations among groups are independent. That is, not paired or repeated measures data</p>
<p>Moderate deviation from normally-distributed residuals is permissible</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#two-way ANOVA</span>
m1 &lt;-<span class="st"> </span><span class="kw">aov</span>(chinese <span class="op">~</span><span class="st"> </span>sex <span class="op">+</span><span class="st"> </span>class, <span class="dt">data =</span> df)
<span class="kw">summary</span>(m1)</code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value Pr(&gt;F)
## sex          1    0.1   0.078   0.004  0.949
## class        3   68.6  22.851   1.213  0.309
## Residuals   95 1790.1  18.843</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m2 &lt;-<span class="st"> </span><span class="kw">aov</span>(chinese <span class="op">~</span><span class="st"> </span>sex <span class="op">*</span><span class="st"> </span>class, <span class="dt">data =</span> df)
<span class="kw">summary</span>(m2)</code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value Pr(&gt;F)
## sex          1    0.1   0.078   0.004  0.949
## class        3   68.6  22.851   1.206  0.312
## sex:class    3   47.5  15.840   0.836  0.477
## Residuals   92 1742.6  18.941</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m3 &lt;-<span class="st"> </span><span class="kw">aov</span>(chinese <span class="op">~</span><span class="st"> </span>sex <span class="op">+</span><span class="st"> </span>class <span class="op">+</span><span class="st"> </span>sex<span class="op">:</span>class, <span class="dt">data =</span> df)<span class="co"># same as model2</span>
<span class="kw">summary</span>(m3)</code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value Pr(&gt;F)
## sex          1    0.1   0.078   0.004  0.949
## class        3   68.6  22.851   1.206  0.312
## sex:class    3   47.5  15.840   0.836  0.477
## Residuals   92 1742.6  18.941</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">TukeyHSD</span>(m1)</code></pre></div>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = chinese ~ sex + class, data = df)
## 
## $sex
##            diff       lwr      upr    p adj
## m-f -0.05706916 -1.816161 1.702023 0.948782
## 
## $class
##           diff       lwr      upr     p adj
## 2-1 -0.1255633 -3.336346 3.085219 0.9996144
## 3-1 -0.4778375 -3.688620 2.732945 0.9798669
## 4-1  1.6464395 -1.564343 4.857222 0.5393779
## 3-2 -0.3522742 -3.563057 2.858508 0.9917167
## 4-2  1.7720028 -1.438779 4.982785 0.4758432
## 4-3  2.1242771 -1.086505 5.335059 0.3139376</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">TukeyHSD</span>(m2)</code></pre></div>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = chinese ~ sex * class, data = df)
## 
## $sex
##            diff       lwr      upr     p adj
## m-f -0.05706916 -1.821469 1.707331 0.9489189
## 
## $class
##           diff       lwr      upr     p adj
## 2-1 -0.1255633 -3.346553 3.095427 0.9996173
## 3-1 -0.4778375 -3.698828 2.743153 0.9800129
## 4-1  1.6464395 -1.574551 4.867430 0.5416465
## 3-2 -0.3522742 -3.573264 2.868716 0.9917777
## 4-2  1.7720028 -1.448987 4.992993 0.4782437
## 4-3  2.1242771 -1.096713 5.345267 0.3164010
## 
## $`sex:class`
##               diff       lwr      upr     p adj
## m:1-f:1 -0.5656825 -6.190508 5.059143 0.9999850
## f:2-f:1  0.1119836 -4.739734 4.963701 1.0000000
## m:2-f:1 -0.9967049 -6.438560 4.445150 0.9991594
## f:3-f:1 -1.3861534 -6.088264 3.315957 0.9839604
## m:3-f:1  0.8230745 -5.022416 6.668565 0.9998524
## f:4-f:1  2.2120321 -2.943206 7.367270 0.8846454
## m:4-f:1  0.7151680 -4.325495 5.755830 0.9998447
## f:2-m:1  0.6776662 -5.014257 6.369589 0.9999524
## m:2-m:1 -0.4310223 -6.633652 5.771607 0.9999988
## f:3-m:1 -0.8204709 -6.385421 4.744479 0.9997992
## m:3-m:1  1.3887571 -5.170860 7.948374 0.9978655
## f:4-m:1  2.7777147 -3.175041 8.730470 0.8325188
## m:4-m:1  1.2808505 -4.572960 7.134662 0.9973706
## m:2-f:2 -1.1086885 -6.619869 4.402492 0.9984591
## f:3-f:2 -1.4981370 -6.280309 3.284035 0.9773026
## m:3-f:2  0.7110909 -5.198992 6.621174 0.9999489
## f:4-f:2  2.1000485 -3.128317 7.328414 0.9156991
## m:4-f:2  0.6031843 -4.512244 5.718613 0.9999554
## f:3-m:2 -0.3894485 -5.769392 4.990495 0.9999984
## m:3-m:2  1.8197794 -4.583634 8.223193 0.9870411
## f:4-m:2  3.2087370 -2.571438 8.988912 0.6731112
## m:4-m:2  1.7118728 -3.966351 7.390097 0.9817504
## m:3-f:3  2.2092279 -3.578670 7.997126 0.9345555
## f:4-f:3  3.5981855 -1.491655 8.688026 0.3657748
## m:4-f:3  2.1013214 -2.872438 7.075081 0.8926730
## f:4-m:3  1.3889576 -4.772730 7.550645 0.9968295
## m:4-m:3 -0.1079065 -6.174058 5.958245 1.0000000
## m:4-f:4 -1.4968642 -6.901022 3.907293 0.9888596</code></pre>
</div>
</div>
<div id="two-categorical-variables-1" class="section level2">
<h2><span class="header-section-number">6.3</span> Two categorical variables</h2>
<div id="chisquare-t-test" class="section level3">
<h3><span class="header-section-number">6.3.1</span> Chisquare t-test</h3>
<p>When our data involves two categorical variables, and we want to know if these two variables are related or independent to each other, we can use the chisquare test.</p>
<p>The null hypothesis of the independence assumption is to be rejected if the p-value of the following Chi-squared test statistics is less than a given significance level α.</p>
<p>Here is an example: In the dataset <em>survey</em>, the Smoke column records the students smoking habit, while the Exer column records their exercise level. The allowed values in Smoke are “Heavy”, “Regul” (regularly), “Occas” (occasionally) and “Never”. As for Exer, they are “Freq” (frequently), “Some” and “None”.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tbl =<span class="st"> </span><span class="kw">table</span>(survey<span class="op">$</span>Smoke, survey<span class="op">$</span>Exer)

<span class="kw">chisq.test</span>(tbl) </code></pre></div>
<pre><code>## Warning in chisq.test(tbl): Chi-squared approximation may be incorrect</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  tbl
## X-squared = 5.4885, df = 6, p-value = 0.4828</code></pre>
<p>As the p-value 0.4828 is greater than the .05 significance level, we do not reject the null hypothesis that the smoking habit is independent of the exercise level of the students.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="covariation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="parametric-tests-and-relevant-assumptions.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/05-Simple_stats.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
